{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('input/dataset_treino.csv')\n",
    "test_data = pd.read_csv('input/dataset_teste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of registers and features\n",
    "print(\"Train shape with Id : {} \".format(train_data.shape))\n",
    "print(\"Test shape with Id : {} \".format(test_data.shape))\n",
    "\n",
    "#id_name='OrderId'\n",
    "\n",
    "#Save the 'Id' column\n",
    "train_ID = train_data['Order']\n",
    "test_ID = test_data['OrderId']\n",
    "test_ID2 = test_data['Property Id'] ## thats the identifier!!! \n",
    "\n",
    "#Now drop the  'Id' colum since it's unnecessary for  the prediction process.\n",
    "train_data.drop('Order', axis = 1, inplace = True)\n",
    "test_data.drop('OrderId', axis = 1, inplace = True)\n",
    "\n",
    "#check again the data size after dropping the 'Id' variable\n",
    "print(\"\\nTrain shape without Id : {} \".format(train_data.shape)) \n",
    "print(\"Test shape without Id : {} \".format(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ENERGY STAR Score'\n",
    "source = 'Source'\n",
    "\n",
    "y_train = train_data[target]\n",
    "features = train_data.columns.tolist()\n",
    "features.remove(target)\n",
    "\n",
    "train_data[source]='Train'\n",
    "test_data[source]='Test'\n",
    "\n",
    "df = pd.concat((train_data, test_data)).reset_index(drop=True)\n",
    "#df.drop([target], axis=1, inplace=True)\n",
    "\n",
    "train_data.drop([source], axis=1, inplace=True)\n",
    "test_data.drop([source], axis=1, inplace=True)\n",
    "\n",
    "print(\"Total dataframe size is : {}\".format(df.shape))\n",
    "\n",
    "#X = df[features]\n",
    "\n",
    "X_train = train_data[features]\n",
    "y_train = train_data[target]\n",
    "X = train_data\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining general info about the dataset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain an overview of the variables\n",
    "import pandas_profiling as pf\n",
    "pf.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan = (df.isnull().sum() / len(df)) * 100\n",
    "missing_data = pd.DataFrame({'Missing n':df.isnull().sum(),'% Missing' :df_nan})\n",
    "missing_data.sort_values('% Missing', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of missing values should be higher. When we look at the data type, some columns that are supposed to be numeric have been classified as object, as they also contain strings. A quick inspection shows that the dataset contains the information 'Not Available', which have caused them to be identofied as strings. So we will correct the data and review the missing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('Not Available',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan = (df.isnull().sum() / len(df)) * 100\n",
    "missing_data = pd.DataFrame({'Missing n':df.isnull().sum(),'% Missing' :df_nan})\n",
    "missing_data.sort_values('% Missing', ascending=False).head(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the strings have been removed from the numeric columns, we can set their type as numeric and further analyze it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_terms=['ft²','kBtu','(therms)','(kWh)','(Metric Tons CO2e)','(kgal)']\n",
    "\n",
    "for col in list(df.columns):\n",
    "    for term in numeric_terms:\n",
    "        if (term in col):\n",
    "            df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By quickly looking at the presented data, plus information about the fields, we conclude that:\n",
    "\n",
    "1) 'NYC Borough, Block and Lot (BBL) self-reported' is equal to 'BBL - 10 digits', where the first digit represents the 'Borough', next five digits 'Tax Block' and last four 'Tax Lot', plus we have already a 'Borough' column in the dataset. -- Since there are only two missing values at 'BBL - 10 digits', but more on the others, I'll check if I can use it to fill in the missing information. This was helpful: https://a836-pts-access.nyc.gov/care/forms/htmlframe.aspx?mode=content/home.htm\n",
    "\n",
    "2) 'Address 1 (self-reported)', 'Address 2', 'Postal Code','Street Name', 'Street Number','Latitude' and 'Longitude' contain information about the localization. I'll keep only 'Postal Code' as it seems to be the most generic information about it, besides 'Borough'. There may be additional or more general information about the location at 'Census Tract', 'Community Board', 'Council District', but for now I'll ignore these as these columns haven't even been described at the documetation file. -- This might be helpful: https://www.health.ny.gov/statistics/cancer/registry/appendix/neighborhoods.htm\n",
    "\n",
    "3) 'Total GHG Emissions (Metric Tons CO2e)'='Direct GHG Emissions (Metric Tons CO2e)'+'Indirect GHG Emissions (Metric Tons CO2e)' --- I'll keep the total and the fraction of direct\n",
    "\n",
    "4) 'Property GFA - Self-Reported (ft²)'='DOF Gross Floor Area', so I'll drop the 'DOF Gross Floor Area' that has missing values\n",
    "\n",
    "5) 'Largest Property Use Type - Gross Floor Area (ft²)','2nd Largest Property Use - Gross Floor Area (ft²)' and\n",
    "'3rd Largest Property Use Type - Gross Floor Area (ft²)' are part of 'Property GFA - Self-Reported (ft²)'--\n",
    "I'll create and keep the fractions they represent and drop the original values\n",
    "\n",
    "5) 'Site EUI (kBtu/ft²)'=('Fuel Oil #1 Use (kBtu)'+'Fuel Oil #2 Use (kBtu)'+'Fuel Oil #4 Use (kBtu)'+\n",
    "                        'Fuel Oil #5 & 6 Use (kBtu)'+'Diesel #2 Use (kBtu)'+'Natural Gas Use (kBtu)'+\n",
    "                        'District Steam Use (kBtu)'+'Electricity Use - Grid Purchase (kBtu)')/ GFA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['BBL - 10 digits'].isnull()]\n",
    "#Shows that id 6656 and 6690 are the ones that have no info on Borough\n",
    "#df.iloc[6656,:] # 'BBL - 10 digits' was NAN. Used Address to locate BBL online ()\n",
    "#df.iloc[6690,:] # 'BBL - 10 digits' was NAN. Used Address to locate BBL online ()\n",
    "#df.iloc[8270,:] #  Has same Postal Code as 6690 but divergent information when looking at website databases. \n",
    "                 # 'BBL - 10 digits' and Postal Code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ix[6656,'BBL - 10 digits'] ='2036420001'\n",
    "df.ix[6690,'BBL - 10 digits'] = '3067130006'\n",
    "df.ix[8270,'BBL - 10 digits'] = '3044240012'\n",
    "df.ix[8270,'Postal Code'] = '10467'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Largest Property Use Rate']=df['Largest Property Use Type - Gross Floor Area (ft²)']/df['Property GFA - Self-Reported (ft²)']\n",
    "df['2nd Property Use Rate']=df['2nd Largest Property Use - Gross Floor Area (ft²)']/df['Property GFA - Self-Reported (ft²)']\n",
    "df['3rd Property Use Rate']=df['3rd Largest Property Use Type - Gross Floor Area (ft²)']/df['Property GFA - Self-Reported (ft²)']\n",
    "df['Direct GHG Emissions Rate']=df['Direct GHG Emissions (Metric Tons CO2e)']/df['Total GHG Emissions (Metric Tons CO2e)']\n",
    "df['BBL - 10 digits'] = df['BBL - 10 digits'].str.extract('(\\d+)', expand=False)\n",
    "df['Borough']=df['BBL - 10 digits'].str[0]\n",
    "df['Tax Block']=df['BBL - 10 digits'].str[1:6]\n",
    "df['Tax Lot']=df['BBL - 10 digits'].str[6:10]\n",
    "df['Postal Code'] = df['Postal Code'].astype(str)\n",
    "df['Year Built'] = df['Year Built'].astype(str)\n",
    "df['Borough'] = df['Borough'].astype(str)\n",
    "df['Tax Block'] = df['Tax Block'].astype(str)\n",
    "df['Tax Lot'] = df['Tax Lot'].astype(str)\n",
    "df['Property Id'] = df['Property Id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan = (df.isnull().sum() / len(df)) * 100\n",
    "missing_data = pd.DataFrame({'Missing n':df.isnull().sum(),'% Missing' :df_nan})\n",
    "missing_data.sort_values('% Missing', ascending=False).head(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a lot of missing values. Here we will convert some missing values into zero because they are actually zero, transform missing values at 2nd and 3rd Property Use Type to 'none' and then drop some of the columns that I believe are irrelevant for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_col=['2nd Property Use Rate','3rd Property Use Rate',\n",
    "            'Water Intensity (All Water Sources) (gal/ft²)','Weather Normalized Site Natural Gas Intensity (therms/ft²)',\n",
    "            'Total GHG Emissions (Metric Tons CO2e)','Weather Normalized Site Electricity Intensity (kWh/ft²)',\n",
    "            'Direct GHG Emissions Rate','Total GHG Emissions (Metric Tons CO2e)'\n",
    "            ]\n",
    "\n",
    "for col in zero_col:\n",
    "    df[col].replace(np.nan,0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_col=['2nd Largest Property Use Type','3rd Largest Property Use Type']\n",
    "\n",
    "for col in prop_col:\n",
    "    df[col].replace(np.nan,'none',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_items=['NYC Borough, Block and Lot (BBL) self-reported',\n",
    "            'NYC Building Identification Number (BIN)',\n",
    "            'BBL - 10 digits',\n",
    "            'Parent Property Name',\n",
    "            'Property Name',\n",
    "            'Address 1 (self-reported)',\n",
    "            'Address 2',\n",
    "            'Street Number',\n",
    "            'Street Name',\n",
    "            'Latitude',\n",
    "            'Longitude',\n",
    "            'DOF Gross Floor Area',\n",
    "            'DOF Benchmarking Submission Status',\n",
    "            'List of All Property Use Types at Property',\n",
    "            'Largest Property Use Type - Gross Floor Area (ft²)',\n",
    "            '2nd Largest Property Use - Gross Floor Area (ft²)',\n",
    "            '3rd Largest Property Use Type - Gross Floor Area (ft²)',                     \n",
    "            'Fuel Oil #1 Use (kBtu)',                                         \n",
    "            'Fuel Oil #2 Use (kBtu)',                                         \n",
    "            'Fuel Oil #4 Use (kBtu)',                                         \n",
    "            'Fuel Oil #5 & 6 Use (kBtu)',                                     \n",
    "            'Diesel #2 Use (kBtu)',                                           \n",
    "            'District Steam Use (kBtu)',                                      \n",
    "            'Natural Gas Use (kBtu)',                                         \n",
    "            'Weather Normalized Site Natural Gas Use (therms)',               \n",
    "            'Electricity Use - Grid Purchase (kBtu)',                         \n",
    "            'Weather Normalized Site Electricity (kWh)',                      \n",
    "            'Direct GHG Emissions (Metric Tons CO2e)',                        \n",
    "            'Indirect GHG Emissions (Metric Tons CO2e)',                      \n",
    "            'Property GFA - Self-Reported (ft²)',                              \n",
    "            'Water Use (All Water Sources) (kgal)', \n",
    "            'Weather Normalized Site EUI (kBtu/ft²)',\n",
    "            'Weather Normalized Source EUI (kBtu/ft²)'\n",
    "           ]\n",
    "\n",
    "df.drop(drop_items, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the correlation and plot the data in s heatmap\n",
    "sns.heatmap(df.corr(),annot=True,cmap='coolwarm',linewidths=0.1,annot_kws={'size':18},fmt='.2f')\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(24,24)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Property Type colums has a lot of values, some that appears more often and others less. I have put them all together, and split into categories that I believed made a bit  of sense, while also looking at their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_type={'Multifamily Housing':'Multifamily Housing',  \n",
    "            'Residence Hall/Dormitory':'Residence Hall/Dormitory',\n",
    "            'Other - Lodging/Residential':'Residence Hall/Dormitory',\n",
    "            'Hotel':'Hotel',\n",
    "            'Adult Education':'College/University',\n",
    "            'College/University':'College/University',\n",
    "            'K-12 School':'College/University',\n",
    "            'Library':'College/University',\n",
    "            'Vocational School':'College/University',\n",
    "            'Other - Education':'College/University',\n",
    "            'Office':'Office',\n",
    "            'Medical Office':'Office',\n",
    "            'Financial Office':'Office',\n",
    "            'Bank Branch':'Office',\n",
    "            'Distribution Center':'Distribution Center',\n",
    "            'Self-Storage Facility':'Distribution Center',\n",
    "            'Wholesale Club/Supercenter':'Distribution Center',\n",
    "            'Non-Refrigerated Warehouse':'Distribution Center',\n",
    "            'Fast Food Restaurant':'Food Service',\n",
    "            'Food Sales':'Food Service',\n",
    "            'Food Service':'Food Service',\n",
    "            'Restaurant':'Food Service',\n",
    "            'Supermarket/Grocery Store':'Food Service',\n",
    "            'Convenience Store without Gas Station':'Food Service',\n",
    "            'Other - Restaurant/Bar':'Food Service',\n",
    "            'Hospital (General Medical & Surgical)':'Senior Care Community',\n",
    "            'Urgent Care/Clinic/Other Outpatient':'Senior Care Community',\n",
    "            'Ambulatory Surgical Center':'Senior Care Community',\n",
    "            'Laboratory':'Senior Care Community',\n",
    "            'Pre-school/Daycare':'Senior Care Community',\n",
    "            'Senior Care Community':'Senior Care Community',\n",
    "            'Outpatient Rehabilitation/Physical Therapy':'Senior Care Community',\n",
    "            'Retail Store':'Retail Store',\n",
    "            'Repair Services (Vehicle, Shoe, Locksmith, etc.)':'Retail Store',\n",
    "            'Mailing Center/Post Office':'Retail Store',\n",
    "            'Automobile Dealership':'Retail Store',\n",
    "            'Mailing Center/Post Office':'Retail Store',\n",
    "            'Personal Services (Health/Beauty, Dry Cleaning...':'Retail Store',\n",
    "            'Enclosed Mall':'Retail Store',\n",
    "            'Other - Mall':'Retail Store',\n",
    "            'Other - Services':'Retail Store',\n",
    "            'Other - Utility':'Retail Store',\n",
    "            'Bar/Nightclub':'Recreation',\n",
    "            'Bowling Alley':'Recreation',\n",
    "            'Fitness Center/Health Club/Gym':'Recreation',\n",
    "            'Other - Recreation':'Recreation',\n",
    "            'Other - Entertainment/Public Assembly':'Recreation',\n",
    "            'Performing Arts':'Recreation',\n",
    "            'Social/Meeting Hall':'Recreation',\n",
    "            'Museum':'Recreation',\n",
    "            'Worship Facility':'Recreation',\n",
    "            'Other':'Other',\n",
    "            'Courthouse':'Other',\n",
    "            'Other - Public Services':'Other',\n",
    "            'Swimming Pool':'Other',\n",
    "            'Parking':'Other',\n",
    "            'Refrigerated Warehouse':'Other',\n",
    "            'Data Center':'Other',\n",
    "            'none':'none'\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Largest Property Use Type']=df['Largest Property Use Type'].map(property_type).astype(str)\n",
    "df['2nd Largest Property Use Type']=df['2nd Largest Property Use Type'].map(property_type).astype(str)\n",
    "df['3rd Largest Property Use Type']=df['3rd Largest Property Use Type'].map(property_type).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train_data['ENERGY STAR Score'],train_data['Largest Property Use Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_droplist=['Metered Areas (Energy)','Metered Areas  (Water)','Release Date','Water Required?','Community Board','Council District','Census Tract','NTA']\n",
    "\n",
    "df.drop(new_droplist, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the numeric columns\n",
    "df_numeric_col = df.select_dtypes('number')\n",
    "df_numeric_feat_col=df_numeric_col.drop('ENERGY STAR Score',axis=1)\n",
    "ycol=df['ENERGY STAR Score']\n",
    "\n",
    "df_feat_col = df.select_dtypes('object')\n",
    "df_feat_col2=df_feat_col.drop(['Borough', 'Largest Property Use Type'],axis=1)\n",
    "\n",
    "# Select the categorical columns\n",
    "df_cat_col = df[['Borough', 'Largest Property Use Type']]\n",
    "\n",
    "# One hot encode\n",
    "df_cat_col = pd.get_dummies(df_cat_col)\n",
    "\n",
    "# Join the two dataframes using concat\n",
    "df_v1_full = pd.concat([ycol,df_feat_col2,df_numeric_feat_col, df_cat_col], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v1_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OrdinalEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_v1_full['n_Postal Code']=le.fit_transform(df_v1_full['Postal Code'])\n",
    "df_v1_full['n_Parent Property Id']=le.fit_transform(df_v1_full['Parent Property Id'])\n",
    "df_v1_full['n_Property Id']=le.fit_transform(df_v1_full['Property Id'])\n",
    "df_v1_full['n_Tax Lot']=le.fit_transform(df_v1_full['Tax Lot'])\n",
    "df_v1_full['n_Tax Block']=le.fit_transform(df_v1_full['Tax Block'])\n",
    "df_v1_full['n_3rd Largest Property Use Type']=le.fit_transform(df_v1_full['3rd Largest Property Use Type'])\n",
    "df_v1_full['n_2nd Largest Property Use Type']=le.fit_transform(df_v1_full['2nd Largest Property Use Type'])\n",
    "df_v1_full['n_Primary Property Type - Self Selected']=le.fit_transform(df_v1_full['Primary Property Type - Self Selected'])\n",
    "\n",
    "#oe = OrdinalEncoder() -- discretize!!\n",
    "df_v1_full['n_Year Built']=le.fit_transform(df_v1_full['Year Built'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection=['Postal Code','Parent Property Id','Property Id','Tax Lot','Tax Block',\n",
    "        '3rd Largest Property Use Type','2nd Largest Property Use Type',\n",
    "        'Primary Property Type - Self Selected','Year Built']\n",
    "\n",
    "df_v1_full=df_v1_full.drop(selection,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,Normalizer,FunctionTransformer,QuantileTransformer,PowerTransformer\n",
    "\n",
    "df_v2=df_v1_full.copy()\n",
    "\n",
    "select=['ENERGY STAR Score',\n",
    "        'Number of Buildings - Self-reported','Occupancy',\n",
    "        'Site EUI (kBtu/ft²)','Source EUI (kBtu/ft²)','Total GHG Emissions (Metric Tons CO2e)',\n",
    "        'Water Intensity (All Water Sources) (gal/ft²)','Weather Normalized Site Electricity Intensity (kWh/ft²)',\n",
    "        'Weather Normalized Site Natural Gas Intensity (therms/ft²)','Largest Property Use Rate',\n",
    "        '2nd Property Use Rate','3rd Property Use Rate','Direct GHG Emissions Rate'\n",
    "       ]\n",
    "\n",
    "df_v2_part= df_v2[select]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "normal = Normalizer()\n",
    "log1p = FunctionTransformer(np.log1p),\n",
    "qtnormal = QuantileTransformer(output_distribution='normal')\n",
    "jtrans =PowerTransformer(method='yeo-johnson')\n",
    "#boxcox = PowerTransformer(method='box-cox')\n",
    "\n",
    "df_v2_part_normalized=pd.DataFrame(scaler.fit_transform(df_v2_part))\n",
    "df_v2_part_transformed=pd.DataFrame(jtrans.fit_transform(df_v2_part_normalized))\n",
    "df_v2_part_transformed.columns=select\n",
    "df_v2[select]=df_v2_part_transformed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_v2_full = df_v1_full\n",
    "selection=['Source EUI (kBtu/ft²)','n_Year Built','n_Parent Property Id','n_Property Id','n_Tax Lot',\n",
    "            'n_Tax Block','n_3rd Largest Property Use Type','n_2nd Largest Property Use Type',\n",
    "            'n_Primary Property Type - Self Selected','n_Year Built','Number of Buildings - Self-reported',\n",
    "            'Occupancy'\n",
    "          ]\n",
    "\n",
    "#df_v1=df_v1_full.drop(selection,axis=1)\n",
    "df_v2=df_v2.drop(selection,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base=df_v2 ### <-\n",
    "df_train = df_base.loc[df_base['Source']=='Train']\n",
    "df_test = df_base.loc[df_base['Source']=='Test']\n",
    "df_train.drop('Source', axis=1, inplace=True)\n",
    "df_test.drop('Source', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def draw_histograms(dataframe, features, rows, cols):\n",
    "    fig=plt.figure(figsize=(15,15))\n",
    "    for i, feature in enumerate(features):\n",
    "        ax=fig.add_subplot(rows,cols,i+1)\n",
    "        dataframe[feature].hist(bins=20,ax=ax,facecolor='midnightblue')\n",
    "        ax.set_title(\"Distribution of \"+feature ,color='DarkRed')\n",
    "        \n",
    "    fig.tight_layout()  \n",
    "    plt.show()\n",
    "draw_histograms(df_v1_full,df_v1_full.columns,15,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['ENERGY STAR Score']\n",
    "X = df_train.drop('ENERGY STAR Score', axis=1)\n",
    "\n",
    "X_TEST = df_test.drop('ENERGY STAR Score', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 100)\n",
    "\n",
    "#X_test=X_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Create the model\n",
    "#gradient_boosted = GradientBoostingRegressor()\n",
    "\n",
    "gradient_boosted=GradientBoostingRegressor(loss='lad', max_depth=5,\n",
    "                          max_features=None,\n",
    "                          min_samples_leaf=6,\n",
    "                          min_samples_split=6,\n",
    "                          n_estimators=500)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gradient_boosted.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = gradient_boosted.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print('Gradient Boosted Performance on the test set: MAE = %0.4f' % mae)\n",
    "#Gradient Boosted Performance on the test set: MAE = 0.3817 df_v2_full qt scaler\n",
    "#Gradient Boosted Performance on the test set: MAE = 0.2817 df_v2_full  scaler\n",
    "#Gradient Boosted Performance on the test set: MAE = 0.2820 df_v2_full  jtrans + scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Create the model\n",
    "gradient_boosted=GradientBoostingRegressor(loss='lad', max_depth=5,\n",
    "                          max_features=None,\n",
    "                          min_samples_leaf=6,\n",
    "                          min_samples_split=6,\n",
    "                          n_estimators=500)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gradient_boosted.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = gradient_boosted.predict(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undo the transformations\n",
    "X_TEST['ENERGY STAR Score'] = predictions\n",
    "df_v2_part_transf = X_TEST[select]\n",
    "transformed=pd.DataFrame(jtrans.inverse_transform(df_v2_part_transf))\n",
    "inverted_columns=pd.DataFrame(scaler.inverse_transform(transformed))\n",
    "predictions2=inverted_columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate submission file\n",
    "predictions2 = [0 if item < 0 else 100 if item > 100 else round(item,0) for item in predictions2]\n",
    "\n",
    "sub_file=[]\n",
    "sub_file=pd.DataFrame(test_ID2)\n",
    "sub_file['score']=predictions2\n",
    "sub_file.to_csv('submission_v2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
